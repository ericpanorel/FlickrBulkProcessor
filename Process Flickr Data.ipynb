{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import zipfile\n",
    "from zipfile import ZipFile\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import time\n",
    "import os\n",
    "import io as sio\n",
    "import json\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check first if photo zipped files are valid!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "currentDir = os.getcwd()\n",
    "allPhotoZips= []\n",
    "badfiles= []\n",
    "allPhotos=[]\n",
    "for filename in glob.iglob('{}/**/*data-download*.zip'.format(currentDir), recursive=True):\n",
    "    allPhotoZips.append(filename)\n",
    "for photoZip in allPhotoZips:\n",
    "    if zipfile.is_zipfile(photoZip)==False:\n",
    "        print('Bad Zip file: {0} . Download again!'.format(photoZip))\n",
    "    else:\n",
    "        with ZipFile(photoZip) as myzip:\n",
    "            for info in myzip.infolist():\n",
    "                if info.file_size==0:\n",
    "                    badfiles.append(info.filename)\n",
    "                    #print('Bad archived file: {0} . Need to download manually'.format(info.filename))\n",
    "                dict={}\n",
    "                dict[\"ZipName\"]=photoZip\n",
    "                dict[\"fileName\"]=str(info.filename)\n",
    "                dict[\"fileSize\"]=int(info.file_size)\n",
    "                allPhotos.append(dict)\n",
    "dfRawPhotos=pd.DataFrame(allPhotos)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfRawPhotos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfRawPhotos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain account data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "currentDir = os.getcwd()\n",
    "allDataZips= []\n",
    "for filename in glob.iglob('{}/**/*_part*.zip'.format(currentDir), recursive=True):\n",
    "    allDataZips.append(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build our photo database from albums.json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allPhotoAlbums=[]\n",
    "for dataZip in allDataZips:\n",
    "    with ZipFile(dataZip) as myzip:\n",
    "        for jsonFile in [k for k in myzip.namelist() if 'albums' in k]:\n",
    "            with myzip.open(jsonFile) as jf:\n",
    "                data=json.load(jf)\n",
    "                albums = data[\"albums\"]\n",
    "                for album in albums:\n",
    "                    for photo in album[\"photos\"]:\n",
    "                        dict={}\n",
    "                        dict[\"albumId\"]=int(album[\"id\"])\n",
    "                        dict[\"albumName\"]=str(album[\"title\"])\n",
    "                        dict[\"albumPhotoId\"]=int(photo)\n",
    "                        allPhotoAlbums.append(dict)\n",
    "dfAlbums = pd.DataFrame(allPhotoAlbums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grp = dfAlbums.groupby('albumName').count()\n",
    "writer = pd.ExcelWriter('albums.xlsx')\n",
    "grp.to_excel(writer,'albums')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quick way to check if all your photos are in album\n",
    "dfAlbums.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build our photo database from photo_nnnnn json files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allphotos=[]\n",
    "for dataZip in allDataZips:\n",
    "    with ZipFile(dataZip) as myzip:\n",
    "        for jsonFile in [k for k in myzip.namelist() if 'photo_' in k]:\n",
    "            with myzip.open(jsonFile) as jf:\n",
    "                data=json.load(jf)\n",
    "                dict={}\n",
    "                dict[\"id\"]=int(data[\"id\"])\n",
    "                dict[\"name\"]=str(data[\"name\"])\n",
    "                url=str(data[\"original\"])\n",
    "                dict[\"original\"]=url\n",
    "                dict[\"filename\"]=url.rsplit('/', 1)[-1]\n",
    "                foo=dfAlbums.loc[dfAlbums['albumPhotoId'] == dict[\"id\"]]\n",
    "                if foo.shape[0]==0:                    \n",
    "                    dict[\"albumId\"]=int(-1)\n",
    "                    dict[\"albumName\"]=\"No Album\"\n",
    "                else:\n",
    "                    # first album found where this photo belongs\n",
    "                    dict[\"albumId\"]= foo.iloc[0]['albumId']\n",
    "                    dict[\"albumName\"]= foo.iloc[0]['albumName']                  \n",
    "                allphotos.append(dict)\n",
    "\n",
    "df = pd.DataFrame(allphotos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This should match your total number of items in Flickr\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if all photos have albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['albumName'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noalbum=(df.loc[df['albumId'] == -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "noalbum.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the albums, lets create folders for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for album in df.groupby('albumName').groups:\n",
    "    directory=os.path.join(os.getcwd(),'Albums',album.strip())\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "# no album\n",
    "directory=os.path.join(os.getcwd(),'Albums',\"No Album\")\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the photos and put them where they belong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    album=row['albumName']\n",
    "    directory=os.path.join(os.getcwd(),'Albums',album.strip())\n",
    "    photoFile=row['filename']\n",
    "    strId=(str(row['id']))\n",
    "    albumData=dfRawPhotos[dfRawPhotos['fileName'].str.contains(strId)]\n",
    "    if albumData.shape[0]==0:\n",
    "        print('No album for {0}'.format(photoFile))\n",
    "    else:\n",
    "        for index2, albumRow in albumData.iterrows():\n",
    "            if albumRow['fileSize']==0:\n",
    "                try:\n",
    "                    urllib.request.urlretrieve(row['original'], os.path.join(directory,albumRow['fileName']))\n",
    "                except Exception as e:\n",
    "                    print('Error {} : {}'.format(row['original'],e))\n",
    "                \n",
    "            else:\n",
    "                with ZipFile(albumRow['ZipName']) as myzip:\n",
    "                    myzip.extract(albumRow['fileName'], directory)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "albumData=dfRawPhotos[dfRawPhotos['fileName'].str.contains('8190541672')]\n",
    "albumData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
